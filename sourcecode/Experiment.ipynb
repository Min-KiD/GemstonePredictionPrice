{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c77aaa3",
   "metadata": {},
   "source": [
    "# For the testing before going to submit\n",
    "\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ba65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf51539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3b5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['cut', 'color', 'clarity']\n",
    "def convert_cat(df, features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].astype('category')\n",
    "convert_cat(train_df, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fca02e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(193562, 10)\n"
     ]
    }
   ],
   "source": [
    "# since there is no row where x = 0 or y = 0 and z is non-zero, so we just need to drop the rows which z = 0\n",
    "print(train_df[train_df['z'] == 0].shape[0])\n",
    "train_df = train_df.drop(train_df[(train_df['z'] == 0) | (train_df['z'] > 30)].index)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa82779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193556, 10)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(train_df[(train_df['z'] <= 2) | (train_df['z'] >= 6) | (train_df['y'] >= 10)].index)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a12d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you testing h2o, please don't run this line\n",
    "\n",
    "train_df['carat'] = np.sqrt(train_df['carat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "094369ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "      <th>diameter</th>\n",
       "      <th>depth_adj</th>\n",
       "      <th>weight_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.232883</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "      <td>7.30</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.424781</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "      <td>8.09</td>\n",
       "      <td>62.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.836660</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "      <td>5.71</td>\n",
       "      <td>61.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565685</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.71</td>\n",
       "      <td>666</td>\n",
       "      <td>4.39</td>\n",
       "      <td>61.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.303840</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.61</td>\n",
       "      <td>4.77</td>\n",
       "      <td>14453</td>\n",
       "      <td>7.63</td>\n",
       "      <td>62.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193568</th>\n",
       "      <td>0.556776</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1130</td>\n",
       "      <td>4.37</td>\n",
       "      <td>61.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193569</th>\n",
       "      <td>0.836660</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2874</td>\n",
       "      <td>5.76</td>\n",
       "      <td>60.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193570</th>\n",
       "      <td>0.854400</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3036</td>\n",
       "      <td>5.74</td>\n",
       "      <td>63.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193571</th>\n",
       "      <td>0.583095</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.81</td>\n",
       "      <td>681</td>\n",
       "      <td>4.47</td>\n",
       "      <td>62.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193572</th>\n",
       "      <td>0.842615</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2258</td>\n",
       "      <td>5.72</td>\n",
       "      <td>60.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193556 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat        cut color clarity  table     x     y     z  price  \\\n",
       "id                                                                          \n",
       "0       1.232883    Premium     F     VS2   58.0  7.27  7.33  4.55  13619   \n",
       "1       1.424781  Very Good     J     SI2   58.0  8.06  8.12  5.05  13387   \n",
       "2       0.836660      Ideal     G     VS1   57.0  5.69  5.73  3.50   2772   \n",
       "3       0.565685      Ideal     G     VS1   56.0  4.38  4.41  2.71    666   \n",
       "4       1.303840    Premium     G     VS2   59.0  7.65  7.61  4.77  14453   \n",
       "...          ...        ...   ...     ...    ...   ...   ...   ...    ...   \n",
       "193568  0.556776      Ideal     D    VVS2   56.0  4.35  4.39  2.67   1130   \n",
       "193569  0.836660    Premium     G    VVS2   58.0  5.75  5.77  3.47   2874   \n",
       "193570  0.854400  Very Good     F     SI1   57.0  5.72  5.75  3.62   3036   \n",
       "193571  0.583095  Very Good     D     SI1   55.0  4.45  4.49  2.81    681   \n",
       "193572  0.842615       Good     E     SI2   64.0  5.73  5.71  3.48   2258   \n",
       "\n",
       "        diameter  depth_adj weight_cat  \n",
       "id                                      \n",
       "0           7.30       62.3          2  \n",
       "1           8.09       62.4          2  \n",
       "2           5.71       61.3          2  \n",
       "3           4.39       61.7          2  \n",
       "4           7.63       62.5          2  \n",
       "...          ...        ...        ...  \n",
       "193568      4.37       61.1          2  \n",
       "193569      5.76       60.2          2  \n",
       "193570      5.74       63.1          2  \n",
       "193571      4.47       62.9          2  \n",
       "193572      5.72       60.8          2  \n",
       "\n",
       "[193556 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['diameter'] = round((train_df.x + train_df.y)/2, 2)\n",
    "train_df['depth_adj'] = round((train_df.z/train_df.diameter)*100, 1)\n",
    "train_df.drop('depth', axis = 1, inplace = True)\n",
    "train_df['weight_cat'] = pd.cut(train_df['carat'],\n",
    "                               bins=[0., 0.5, 1.5, np.inf],\n",
    "                               labels=[1, 2, 3])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d930f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cut', 'color', 'clarity', 'weight_cat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = ['carat', 'depth_adj', 'table','x', 'y', 'z', 'diameter']\n",
    "cat_features.append('weight_cat')\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4814ffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carat', 'depth_adj', 'table', 'x', 'y', 'z', 'diameter', 'esti_volume']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df['esti_volume'] = round(train_df.z*train_df.y*train_df.x, 2)\n",
    "# num_features.append('esti_volume')\n",
    "# num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9302fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# change test_size to 0.6 if you wotk with model testing, 0.2 for optuna testing\n",
    "\n",
    "spliting = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=21)\n",
    "for use_index, leave_index in spliting.split(train_df, train_df['weight_cat']):\n",
    "    stra_use_set = train_df.iloc[use_index]\n",
    "    stra_leave_set = train_df.iloc[leave_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b530316",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = stra_use_set['price']\n",
    "X = stra_use_set.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e7d7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = [['Ideal', 'Premium', 'Very Good', 'Good', 'Fair'], \n",
    "                  ['D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "                  ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'I1'],\n",
    "                  ['1', '2', '3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb9ed3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(steps =[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('encoder', OrdinalEncoder(categories = category_order))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75517d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;carat&#x27;, &#x27;depth_adj&#x27;, &#x27;table&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;,\n",
       "                                  &#x27;diameter&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  OrdinalEncoder(categories=[[&#x27;Fair&#x27;,\n",
       "                                                                              &#x27;Good&#x27;,\n",
       "                                                                              &#x27;Very &#x27;\n",
       "                                                                              &#x27;Good&#x27;,\n",
       "                                                                              &#x27;Premium&#x27;,\n",
       "                                                                              &#x27;Ideal&#x27;],\n",
       "                                                                             [&#x27;D&#x27;,\n",
       "                                                                              &#x27;E&#x27;,\n",
       "                                                                              &#x27;F&#x27;,\n",
       "                                                                              &#x27;G&#x27;,\n",
       "                                                                              &#x27;H&#x27;,\n",
       "                                                                              &#x27;I&#x27;,\n",
       "                                                                              &#x27;J&#x27;],\n",
       "                                                                             [&#x27;IF&#x27;,\n",
       "                                                                              &#x27;VVS1&#x27;,\n",
       "                                                                              &#x27;VVS2&#x27;,\n",
       "                                                                              &#x27;VS1&#x27;,\n",
       "                                                                              &#x27;VS2&#x27;,\n",
       "                                                                              &#x27;SI1&#x27;,\n",
       "                                                                              &#x27;SI2&#x27;,\n",
       "                                                                              &#x27;I1&#x27;],\n",
       "                                                                             [&#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;]]))]),\n",
       "                                 [&#x27;cut&#x27;, &#x27;color&#x27;, &#x27;clarity&#x27;, &#x27;weight_cat&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;carat&#x27;, &#x27;depth_adj&#x27;, &#x27;table&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;,\n",
       "                                  &#x27;diameter&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  OrdinalEncoder(categories=[[&#x27;Fair&#x27;,\n",
       "                                                                              &#x27;Good&#x27;,\n",
       "                                                                              &#x27;Very &#x27;\n",
       "                                                                              &#x27;Good&#x27;,\n",
       "                                                                              &#x27;Premium&#x27;,\n",
       "                                                                              &#x27;Ideal&#x27;],\n",
       "                                                                             [&#x27;D&#x27;,\n",
       "                                                                              &#x27;E&#x27;,\n",
       "                                                                              &#x27;F&#x27;,\n",
       "                                                                              &#x27;G&#x27;,\n",
       "                                                                              &#x27;H&#x27;,\n",
       "                                                                              &#x27;I&#x27;,\n",
       "                                                                              &#x27;J&#x27;],\n",
       "                                                                             [&#x27;IF&#x27;,\n",
       "                                                                              &#x27;VVS1&#x27;,\n",
       "                                                                              &#x27;VVS2&#x27;,\n",
       "                                                                              &#x27;VS1&#x27;,\n",
       "                                                                              &#x27;VS2&#x27;,\n",
       "                                                                              &#x27;SI1&#x27;,\n",
       "                                                                              &#x27;SI2&#x27;,\n",
       "                                                                              &#x27;I1&#x27;],\n",
       "                                                                             [&#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;]]))]),\n",
       "                                 [&#x27;cut&#x27;, &#x27;color&#x27;, &#x27;clarity&#x27;, &#x27;weight_cat&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;carat&#x27;, &#x27;depth_adj&#x27;, &#x27;table&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;, &#x27;diameter&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;cut&#x27;, &#x27;color&#x27;, &#x27;clarity&#x27;, &#x27;weight_cat&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;Fair&#x27;, &#x27;Good&#x27;, &#x27;Very Good&#x27;, &#x27;Premium&#x27;, &#x27;Ideal&#x27;],\n",
       "                           [&#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;, &#x27;H&#x27;, &#x27;I&#x27;, &#x27;J&#x27;],\n",
       "                           [&#x27;IF&#x27;, &#x27;VVS1&#x27;, &#x27;VVS2&#x27;, &#x27;VS1&#x27;, &#x27;VS2&#x27;, &#x27;SI1&#x27;, &#x27;SI2&#x27;,\n",
       "                            &#x27;I1&#x27;],\n",
       "                           [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;]])</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                 ['carat', 'depth_adj', 'table', 'x', 'y', 'z',\n",
       "                                  'diameter']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('encoder',\n",
       "                                                  OrdinalEncoder(categories=[['Fair',\n",
       "                                                                              'Good',\n",
       "                                                                              'Very '\n",
       "                                                                              'Good',\n",
       "                                                                              'Premium',\n",
       "                                                                              'Ideal'],\n",
       "                                                                             ['D',\n",
       "                                                                              'E',\n",
       "                                                                              'F',\n",
       "                                                                              'G',\n",
       "                                                                              'H',\n",
       "                                                                              'I',\n",
       "                                                                              'J'],\n",
       "                                                                             ['IF',\n",
       "                                                                              'VVS1',\n",
       "                                                                              'VVS2',\n",
       "                                                                              'VS1',\n",
       "                                                                              'VS2',\n",
       "                                                                              'SI1',\n",
       "                                                                              'SI2',\n",
       "                                                                              'I1'],\n",
       "                                                                             ['1',\n",
       "                                                                              '2',\n",
       "                                                                              '3']]))]),\n",
       "                                 ['cut', 'color', 'clarity', 'weight_cat'])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007b61e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154844, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessor.transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f09b13",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d765887c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "      <th>diameter</th>\n",
       "      <th>depth_adj</th>\n",
       "      <th>weight_cat</th>\n",
       "      <th>esti_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.232883</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "      <td>7.30</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2</td>\n",
       "      <td>242.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.424781</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "      <td>8.09</td>\n",
       "      <td>62.4</td>\n",
       "      <td>2</td>\n",
       "      <td>330.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.836660</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "      <td>5.71</td>\n",
       "      <td>61.3</td>\n",
       "      <td>2</td>\n",
       "      <td>114.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565685</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.71</td>\n",
       "      <td>666</td>\n",
       "      <td>4.39</td>\n",
       "      <td>61.7</td>\n",
       "      <td>2</td>\n",
       "      <td>52.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.303840</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.61</td>\n",
       "      <td>4.77</td>\n",
       "      <td>14453</td>\n",
       "      <td>7.63</td>\n",
       "      <td>62.5</td>\n",
       "      <td>2</td>\n",
       "      <td>277.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193568</th>\n",
       "      <td>0.556776</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1130</td>\n",
       "      <td>4.37</td>\n",
       "      <td>61.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193569</th>\n",
       "      <td>0.836660</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2874</td>\n",
       "      <td>5.76</td>\n",
       "      <td>60.2</td>\n",
       "      <td>2</td>\n",
       "      <td>115.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193570</th>\n",
       "      <td>0.854400</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3036</td>\n",
       "      <td>5.74</td>\n",
       "      <td>63.1</td>\n",
       "      <td>2</td>\n",
       "      <td>119.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193571</th>\n",
       "      <td>0.583095</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.81</td>\n",
       "      <td>681</td>\n",
       "      <td>4.47</td>\n",
       "      <td>62.9</td>\n",
       "      <td>2</td>\n",
       "      <td>56.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193572</th>\n",
       "      <td>0.842615</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2258</td>\n",
       "      <td>5.72</td>\n",
       "      <td>60.8</td>\n",
       "      <td>2</td>\n",
       "      <td>113.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193556 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat        cut color clarity  table     x     y     z  price  \\\n",
       "id                                                                          \n",
       "0       1.232883    Premium     F     VS2   58.0  7.27  7.33  4.55  13619   \n",
       "1       1.424781  Very Good     J     SI2   58.0  8.06  8.12  5.05  13387   \n",
       "2       0.836660      Ideal     G     VS1   57.0  5.69  5.73  3.50   2772   \n",
       "3       0.565685      Ideal     G     VS1   56.0  4.38  4.41  2.71    666   \n",
       "4       1.303840    Premium     G     VS2   59.0  7.65  7.61  4.77  14453   \n",
       "...          ...        ...   ...     ...    ...   ...   ...   ...    ...   \n",
       "193568  0.556776      Ideal     D    VVS2   56.0  4.35  4.39  2.67   1130   \n",
       "193569  0.836660    Premium     G    VVS2   58.0  5.75  5.77  3.47   2874   \n",
       "193570  0.854400  Very Good     F     SI1   57.0  5.72  5.75  3.62   3036   \n",
       "193571  0.583095  Very Good     D     SI1   55.0  4.45  4.49  2.81    681   \n",
       "193572  0.842615       Good     E     SI2   64.0  5.73  5.71  3.48   2258   \n",
       "\n",
       "        diameter  depth_adj weight_cat  esti_volume  \n",
       "id                                                   \n",
       "0           7.30       62.3          2       242.47  \n",
       "1           8.09       62.4          2       330.51  \n",
       "2           5.71       61.3          2       114.11  \n",
       "3           4.39       61.7          2        52.35  \n",
       "4           7.63       62.5          2       277.69  \n",
       "...          ...        ...        ...          ...  \n",
       "193568      4.37       61.1          2        50.99  \n",
       "193569      5.76       60.2          2       115.13  \n",
       "193570      5.74       63.1          2       119.06  \n",
       "193571      4.47       62.9          2        56.15  \n",
       "193572      5.72       60.8          2       113.86  \n",
       "\n",
       "[193556 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# def display_scores(scores):\n",
    "#     print(\"Scores:\", scores)\n",
    "#     print(\"Mean:\", scores.mean())\n",
    "#     print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "# forest_reg = RandomForestRegressor(random_state=1)\n",
    "\n",
    "\n",
    "# forest_scores = cross_val_score(forest_reg, X, y,                          \n",
    "#                              scoring=\"neg_mean_squared_error\", cv=5)\n",
    "# forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "# display_scores(forest_rmse_scores)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c74fcffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54196, 11), (23228, 11))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state = 1)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a96ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# rf_reg = RandomForestRegressor(random_state = 21)\n",
    "# rf_reg.fit(X_train, y_train)\n",
    "# y_pred = rf_reg.predict(X_val)\n",
    "# rf_mse = mean_squared_error(y_val, y_pred)\n",
    "# rf_rmse = np.sqrt(rf_mse)\n",
    "# rf_rmse\n",
    "def plot_correlation_heatmap(df, title_name: str='Train correlation'):\n",
    "    \"\"\"Draws the correlation heatmap plot.\n",
    "    \n",
    "    Args:\n",
    "        df: train or test dataframes\n",
    "        title_name: 'Train' or 'Test' (default 'Train correlation')\n",
    "        \n",
    "    Returns:\n",
    "        subplots of size (len(col_list), 2)\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr()\n",
    "    fig, axes = plt.subplots(figsize=(20, 10))\n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(corr, mask=mask, linewidths=.5, cmap='Blues', annot=True)\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n",
    "\n",
    "#plot_correlation_heatmap(origin, 'Original Dataset Correlation')\n",
    "plot_correlation_heatmap(train_df, 'Train Dataset Correlation')\n",
    "#plot_correlation_heatmap(train, 'Test Dataset Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b840633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612.8088370857007"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgb = XGBRegressor(random_state = 21)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_val)\n",
    "xgb_mse = mean_squared_error(y_val, y_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b491602",
   "metadata": {},
   "source": [
    "# Submission testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c8918120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((193556, 12), (193556,))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final = train_df.drop('price', axis = 1)\n",
    "y_final = train_df['price']\n",
    "X_final.shape, y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d1a947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "20904cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['esti_volume'] = round(test_df.z*test_df.y*test_df.x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9fafba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129050 entries, 193573 to 322622\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   carat        129050 non-null  float64 \n",
      " 1   cut          129050 non-null  category\n",
      " 2   color        129050 non-null  category\n",
      " 3   clarity      129050 non-null  category\n",
      " 4   table        129050 non-null  float64 \n",
      " 5   x            129050 non-null  float64 \n",
      " 6   y            129050 non-null  float64 \n",
      " 7   z            129050 non-null  float64 \n",
      " 8   esti_volume  129050 non-null  float64 \n",
      " 9   diameter     129050 non-null  float64 \n",
      " 10  depth_adj    129050 non-null  float64 \n",
      " 11  weight_cat   129050 non-null  category\n",
      "dtypes: category(4), float64(8)\n",
      "memory usage: 13.4 MB\n"
     ]
    }
   ],
   "source": [
    "test_df['diameter'] = round((test_df.x + test_df.y)/2, 2)\n",
    "test_df['depth_adj'] = round((test_df.z/test_df.diameter)*100, 1)\n",
    "\n",
    "null_rows = test_df[test_df['depth_adj'].isnull()]\n",
    "null_index = null_rows.index\n",
    "test_df.loc[null_index, 'depth_adj'] = null_rows['depth']\n",
    "\n",
    "test_df.drop('depth', axis = 1, inplace = True)\n",
    "\n",
    "test_df['carat'] = np.sqrt(test_df['carat'])\n",
    "\n",
    "test_df['weight_cat'] = pd.cut(test_df['carat'],\n",
    "                               bins=[0., 0.5, 1.5, np.inf],\n",
    "                               labels=[1, 2, 3])\n",
    "\n",
    "convert_cat(test_df, cat_features)\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "927570b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X_final)\n",
    "X_final = preprocessor.transform(X_final)\n",
    "X_test = preprocessor.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ef4485ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193573</td>\n",
       "      <td>876.113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193574</td>\n",
       "      <td>2461.066406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193575</td>\n",
       "      <td>2328.549072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193576</td>\n",
       "      <td>869.824341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193577</td>\n",
       "      <td>5830.035645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129045</th>\n",
       "      <td>322618</td>\n",
       "      <td>3834.853271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129046</th>\n",
       "      <td>322619</td>\n",
       "      <td>2611.011230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129047</th>\n",
       "      <td>322620</td>\n",
       "      <td>7546.550293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129048</th>\n",
       "      <td>322621</td>\n",
       "      <td>5632.525391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129049</th>\n",
       "      <td>322622</td>\n",
       "      <td>4231.782227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129050 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        price\n",
       "0       193573   876.113281\n",
       "1       193574  2461.066406\n",
       "2       193575  2328.549072\n",
       "3       193576   869.824341\n",
       "4       193577  5830.035645\n",
       "...        ...          ...\n",
       "129045  322618  3834.853271\n",
       "129046  322619  2611.011230\n",
       "129047  322620  7546.550293\n",
       "129048  322621  5632.525391\n",
       "129049  322622  4231.782227\n",
       "\n",
       "[129050 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "best_params_xgb = {'tree_method': 'gpu_hist',\n",
    "                   'reg_lambda': 2.553793950847241,\n",
    "                   'colsample_bytree': 0.9,\n",
    "                   'colsample_bylevel': 0.8,\n",
    "                   'subsample': 0.9,\n",
    "                   'learning_rate': 0.04480245593299995,\n",
    "                   'n_estimators': 150,\n",
    "                   'max_depth': 9,\n",
    "                   'min_child_weight': 3,\n",
    "                   'grow_policy': 'lossguide'}\n",
    "\n",
    "model_reg1 = XGBRegressor(**best_params_xgb, random_state=21)\n",
    "model_reg1.fit(X_final, y_final)\n",
    "y_pred1 = model_reg1.predict(X_test)\n",
    "\n",
    "df_prediction = pd.DataFrame({'id': test_df.index,\n",
    "                       'price': y_pred1})\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47f73d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f6a4a",
   "metadata": {},
   "source": [
    "## h2o testing \n",
    "\n",
    "`h2o_pre2.csv` result by not taking sqrt(carat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f015fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = train_df.drop('price', axis = 1)\n",
    "y_final = train_df['price']\n",
    "\n",
    "preprocessor.fit(X_final)\n",
    "X_final = preprocessor.transform(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "240c7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_reshaped = y_final.values.reshape(-1, 1)\n",
    "\n",
    "combined_array = np.hstack((X_final, y_final_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ba08028",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_col = list(num_features)\n",
    "pre_col += cat_features\n",
    "pre_col.append('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92b029ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproces_df = pd.DataFrame(combined_array, columns=pre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea88e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth_adj</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>diameter</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>weight_cat</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.576937</td>\n",
       "      <td>0.444636</td>\n",
       "      <td>0.402574</td>\n",
       "      <td>1.401939</td>\n",
       "      <td>1.461007</td>\n",
       "      <td>1.482353</td>\n",
       "      <td>1.431587</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13619.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.679538</td>\n",
       "      <td>0.536302</td>\n",
       "      <td>0.402574</td>\n",
       "      <td>2.114283</td>\n",
       "      <td>2.177890</td>\n",
       "      <td>2.212002</td>\n",
       "      <td>2.146311</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.195871</td>\n",
       "      <td>-0.472033</td>\n",
       "      <td>-0.118584</td>\n",
       "      <td>-0.022749</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>-0.049908</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.017417</td>\n",
       "      <td>-0.105366</td>\n",
       "      <td>-0.639742</td>\n",
       "      <td>-1.203978</td>\n",
       "      <td>-1.188734</td>\n",
       "      <td>-1.202753</td>\n",
       "      <td>-1.201129</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.966090</td>\n",
       "      <td>0.627969</td>\n",
       "      <td>0.923732</td>\n",
       "      <td>1.744585</td>\n",
       "      <td>1.715092</td>\n",
       "      <td>1.803399</td>\n",
       "      <td>1.730143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193551</th>\n",
       "      <td>-1.039036</td>\n",
       "      <td>-0.655367</td>\n",
       "      <td>-0.639742</td>\n",
       "      <td>-1.231029</td>\n",
       "      <td>-1.206883</td>\n",
       "      <td>-1.261125</td>\n",
       "      <td>-1.219224</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193552</th>\n",
       "      <td>-0.195871</td>\n",
       "      <td>-1.480368</td>\n",
       "      <td>0.402574</td>\n",
       "      <td>0.031353</td>\n",
       "      <td>0.045392</td>\n",
       "      <td>-0.093687</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193553</th>\n",
       "      <td>-0.131012</td>\n",
       "      <td>1.177970</td>\n",
       "      <td>-0.118584</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.027243</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.020234</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193554</th>\n",
       "      <td>-0.974177</td>\n",
       "      <td>0.994637</td>\n",
       "      <td>-1.160900</td>\n",
       "      <td>-1.140859</td>\n",
       "      <td>-1.116138</td>\n",
       "      <td>-1.056823</td>\n",
       "      <td>-1.128752</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193555</th>\n",
       "      <td>-0.174252</td>\n",
       "      <td>-0.930367</td>\n",
       "      <td>3.529523</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>-0.009054</td>\n",
       "      <td>-0.079094</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2258.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193556 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat  depth_adj     table         x         y         z  diameter  \\\n",
       "0       1.576937   0.444636  0.402574  1.401939  1.461007  1.482353  1.431587   \n",
       "1       2.679538   0.536302  0.402574  2.114283  2.177890  2.212002  2.146311   \n",
       "2      -0.195871  -0.472033 -0.118584 -0.022749  0.009094 -0.049908 -0.006907   \n",
       "3      -1.017417  -0.105366 -0.639742 -1.203978 -1.188734 -1.202753 -1.201129   \n",
       "4       1.966090   0.627969  0.923732  1.744585  1.715092  1.803399  1.730143   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "193551 -1.039036  -0.655367 -0.639742 -1.231029 -1.206883 -1.261125 -1.219224   \n",
       "193552 -0.195871  -1.480368  0.402574  0.031353  0.045392 -0.093687  0.038328   \n",
       "193553 -0.131012   1.177970 -0.118584  0.004302  0.027243  0.125207  0.020234   \n",
       "193554 -0.974177   0.994637 -1.160900 -1.140859 -1.116138 -1.056823 -1.128752   \n",
       "193555 -0.174252  -0.930367  3.529523  0.013319 -0.009054 -0.079094  0.002140   \n",
       "\n",
       "        cut  color  clarity  weight_cat    price  \n",
       "0       3.0    2.0      4.0         2.0  13619.0  \n",
       "1       2.0    6.0      6.0         2.0  13387.0  \n",
       "2       4.0    3.0      3.0         1.0   2772.0  \n",
       "3       4.0    3.0      3.0         0.0    666.0  \n",
       "4       3.0    3.0      4.0         2.0  14453.0  \n",
       "...     ...    ...      ...         ...      ...  \n",
       "193551  4.0    0.0      2.0         0.0   1130.0  \n",
       "193552  3.0    3.0      2.0         1.0   2874.0  \n",
       "193553  2.0    2.0      5.0         1.0   3036.0  \n",
       "193554  2.0    0.0      5.0         0.0    681.0  \n",
       "193555  1.0    1.0      6.0         1.0   2258.0  \n",
       "\n",
       "[193556 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproces_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "319dd313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "h2o_frame = h2o.H2OFrame(preproces_df)\n",
    "x = h2o_frame.columns\n",
    "y = 'price'\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f460ab7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |â–ˆ\n",
      "21:37:13.564: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_AllModels_3_AutoML_9_20230703_213713\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>cross_validation</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>5/13</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>4/7</td></tr>\n",
       "<tr><td># DeepLearning base models (used / total)</td>\n",
       "<td>1/3</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>0/2</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>0/1</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>Random</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 305677.27742834686\n",
       "RMSE: 552.880889006255\n",
       "MAE: 280.2180937112729\n",
       "RMSLE: 0.1041387055319953\n",
       "Mean Residual Deviance: 305677.27742834686\n",
       "R^2: 0.9809416031948601\n",
       "Null degrees of freedom: 9979\n",
       "Residual degrees of freedom: 9974\n",
       "Null deviance: 160069800376.9878\n",
       "Residual deviance: 3050659228.7349014\n",
       "AIC: 154386.25917399614</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 327070.75307797635\n",
       "RMSE: 571.9009993678769\n",
       "MAE: 292.77080146463805\n",
       "RMSLE: 0.10663519760821676\n",
       "Mean Residual Deviance: 327070.75307797635\n",
       "R^2: 0.9798972359226116\n",
       "Null degrees of freedom: 193555\n",
       "Residual degrees of freedom: 193550\n",
       "Null deviance: 3149200885738.158\n",
       "Residual deviance: 63306506682.76079\n",
       "AIC: 3007063.0203164625</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>mae</td>\n",
       "<td>292.76633</td>\n",
       "<td>2.9763322</td>\n",
       "<td>292.5225</td>\n",
       "<td>295.94843</td>\n",
       "<td>292.08505</td>\n",
       "<td>288.3033</td>\n",
       "<td>294.97232</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>327059.97</td>\n",
       "<td>9453.96</td>\n",
       "<td>320256.25</td>\n",
       "<td>341555.72</td>\n",
       "<td>327579.44</td>\n",
       "<td>317161.66</td>\n",
       "<td>328746.72</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>327059.97</td>\n",
       "<td>9453.96</td>\n",
       "<td>320256.25</td>\n",
       "<td>341555.72</td>\n",
       "<td>327579.44</td>\n",
       "<td>317161.66</td>\n",
       "<td>328746.72</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>629840150000.0000000</td>\n",
       "<td>6134625800.0000000</td>\n",
       "<td>633609390000.0000000</td>\n",
       "<td>634836550000.0000000</td>\n",
       "<td>626659430000.0000000</td>\n",
       "<td>620503630000.0000000</td>\n",
       "<td>633591890000.0000000</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9798982</td>\n",
       "<td>0.0005092</td>\n",
       "<td>0.9803708</td>\n",
       "<td>0.9791604</td>\n",
       "<td>0.9796474</td>\n",
       "<td>0.9803479</td>\n",
       "<td>0.9799646</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>12661301200.0000000</td>\n",
       "<td>388089312.0000000</td>\n",
       "<td>12436190200.0000000</td>\n",
       "<td>13229477900.0000000</td>\n",
       "<td>12753649700.0000000</td>\n",
       "<td>12192962600.0000000</td>\n",
       "<td>12694225900.0000000</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>571.8441</td>\n",
       "<td>8.235933</td>\n",
       "<td>565.91187</td>\n",
       "<td>584.4277</td>\n",
       "<td>572.3456</td>\n",
       "<td>563.1711</td>\n",
       "<td>573.3644</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1066319</td>\n",
       "<td>0.0007796</td>\n",
       "<td>0.1056679</td>\n",
       "<td>0.1074035</td>\n",
       "<td>0.1072774</td>\n",
       "<td>0.1059654</td>\n",
       "<td>0.1068452</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_AllModels_3_AutoML_9_20230703_213713\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                        value\n",
       "-----------------------------------------  ----------------\n",
       "Stacking strategy                          cross_validation\n",
       "Number of base models (used / total)       5/13\n",
       "# GBM base models (used / total)           4/7\n",
       "# DeepLearning base models (used / total)  1/3\n",
       "# DRF base models (used / total)           0/2\n",
       "# GLM base models (used / total)           0/1\n",
       "Metalearner algorithm                      GLM\n",
       "Metalearner fold assignment scheme         Random\n",
       "Metalearner nfolds                         5\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters         None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 305677.27742834686\n",
       "RMSE: 552.880889006255\n",
       "MAE: 280.2180937112729\n",
       "RMSLE: 0.1041387055319953\n",
       "Mean Residual Deviance: 305677.27742834686\n",
       "R^2: 0.9809416031948601\n",
       "Null degrees of freedom: 9979\n",
       "Residual degrees of freedom: 9974\n",
       "Null deviance: 160069800376.9878\n",
       "Residual deviance: 3050659228.7349014\n",
       "AIC: 154386.25917399614\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 327070.75307797635\n",
       "RMSE: 571.9009993678769\n",
       "MAE: 292.77080146463805\n",
       "RMSLE: 0.10663519760821676\n",
       "Mean Residual Deviance: 327070.75307797635\n",
       "R^2: 0.9798972359226116\n",
       "Null degrees of freedom: 193555\n",
       "Residual degrees of freedom: 193550\n",
       "Null deviance: 3149200885738.158\n",
       "Residual deviance: 63306506682.76079\n",
       "AIC: 3007063.0203164625\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                        mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     292.766      2.97633      292.522       295.948       292.085       288.303       294.972\n",
       "mean_residual_deviance  327060       9453.96      320256        341556        327579        317162        328747\n",
       "mse                     327060       9453.96      320256        341556        327579        317162        328747\n",
       "null_deviance           6.2984e+11   6.13463e+09  6.33609e+11   6.34837e+11   6.26659e+11   6.20504e+11   6.33592e+11\n",
       "r2                      0.979898     0.000509228  0.980371      0.97916       0.979647      0.980348      0.979965\n",
       "residual_deviance       1.26613e+10  3.88089e+08  1.24362e+10   1.32295e+10   1.27536e+10   1.2193e+10    1.26942e+10\n",
       "rmse                    571.844      8.23593      565.912       584.428       572.346       563.171       573.364\n",
       "rmsle                   0.106632     0.000779589  0.105668      0.107404      0.107277      0.105965      0.106845\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml3 = H2OAutoML(sort_metric='rmse', max_runtime_secs=180, seed=1)\n",
    "aml3.train(x=x, y=y, training_frame=h2o_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e88d554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">   mse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">   rmsle</th><th style=\"text-align: right;\">  mean_residual_deviance</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_9_20230703_213713   </td><td style=\"text-align: right;\">571.901</td><td style=\"text-align: right;\">327071</td><td style=\"text-align: right;\">292.771</td><td style=\"text-align: right;\">0.106635</td><td style=\"text-align: right;\">                  327071</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_9_20230703_213713   </td><td style=\"text-align: right;\">571.91 </td><td style=\"text-align: right;\">327081</td><td style=\"text-align: right;\">292.769</td><td style=\"text-align: right;\">0.106637</td><td style=\"text-align: right;\">                  327081</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_9_20230703_213713   </td><td style=\"text-align: right;\">572.222</td><td style=\"text-align: right;\">327439</td><td style=\"text-align: right;\">292.673</td><td style=\"text-align: right;\">0.106392</td><td style=\"text-align: right;\">                  327439</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_9_20230703_213713</td><td style=\"text-align: right;\">572.576</td><td style=\"text-align: right;\">327843</td><td style=\"text-align: right;\">294.452</td><td style=\"text-align: right;\">0.108022</td><td style=\"text-align: right;\">                  327843</td></tr>\n",
       "<tr><td>GBM_2_AutoML_9_20230703_213713                         </td><td style=\"text-align: right;\">573.521</td><td style=\"text-align: right;\">328926</td><td style=\"text-align: right;\">294.05 </td><td style=\"text-align: right;\">0.107381</td><td style=\"text-align: right;\">                  328926</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_9_20230703_213713</td><td style=\"text-align: right;\">573.555</td><td style=\"text-align: right;\">328965</td><td style=\"text-align: right;\">294.197</td><td style=\"text-align: right;\">0.107506</td><td style=\"text-align: right;\">                  328965</td></tr>\n",
       "<tr><td>GBM_3_AutoML_9_20230703_213713                         </td><td style=\"text-align: right;\">574.254</td><td style=\"text-align: right;\">329768</td><td style=\"text-align: right;\">293.407</td><td style=\"text-align: right;\">0.106332</td><td style=\"text-align: right;\">                  329768</td></tr>\n",
       "<tr><td>GBM_5_AutoML_9_20230703_213713                         </td><td style=\"text-align: right;\">574.463</td><td style=\"text-align: right;\">330007</td><td style=\"text-align: right;\">296.112</td><td style=\"text-align: right;\">0.109008</td><td style=\"text-align: right;\">                  330007</td></tr>\n",
       "<tr><td>GBM_1_AutoML_9_20230703_213713                         </td><td style=\"text-align: right;\">575.862</td><td style=\"text-align: right;\">331617</td><td style=\"text-align: right;\">292.196</td><td style=\"text-align: right;\">0.104697</td><td style=\"text-align: right;\">                  331617</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_9_20230703_213713</td><td style=\"text-align: right;\">575.967</td><td style=\"text-align: right;\">331738</td><td style=\"text-align: right;\">292.602</td><td style=\"text-align: right;\">0.105054</td><td style=\"text-align: right;\">                  331738</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    rmse     mse      mae     rmsle    mean_residual_deviance\n",
       "-------------------------------------------------------  -------  ------  -------  --------  ------------------------\n",
       "StackedEnsemble_AllModels_3_AutoML_9_20230703_213713     571.901  327071  292.771  0.106635                    327071\n",
       "StackedEnsemble_AllModels_2_AutoML_9_20230703_213713     571.91   327081  292.769  0.106637                    327081\n",
       "StackedEnsemble_AllModels_1_AutoML_9_20230703_213713     572.222  327439  292.673  0.106392                    327439\n",
       "StackedEnsemble_BestOfFamily_3_AutoML_9_20230703_213713  572.576  327843  294.452  0.108022                    327843\n",
       "GBM_2_AutoML_9_20230703_213713                           573.521  328926  294.05   0.107381                    328926\n",
       "StackedEnsemble_BestOfFamily_2_AutoML_9_20230703_213713  573.555  328965  294.197  0.107506                    328965\n",
       "GBM_3_AutoML_9_20230703_213713                           574.254  329768  293.407  0.106332                    329768\n",
       "GBM_5_AutoML_9_20230703_213713                           574.463  330007  296.112  0.109008                    330007\n",
       "GBM_1_AutoML_9_20230703_213713                           575.862  331617  292.196  0.104697                    331617\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_9_20230703_213713  575.967  331738  292.602  0.105054                    331738\n",
       "[10 rows x 6 columns]\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml3.leaderboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8acfe09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', index_col = 'id')\n",
    "\n",
    "test_df['diameter'] = round((test_df.x + test_df.y)/2, 2)\n",
    "test_df['depth_adj'] = round((test_df.z/test_df.diameter)*100, 1)\n",
    "\n",
    "null_rows = test_df[test_df['depth_adj'].isnull()]\n",
    "null_index = null_rows.index\n",
    "test_df.loc[null_index, 'depth_adj'] = null_rows['depth']\n",
    "\n",
    "test_df.drop('depth', axis = 1, inplace = True)\n",
    "\n",
    "# test_df['carat'] = np.sqrt(test_df['carat'])\n",
    "\n",
    "test_df['weight_cat'] = pd.cut(test_df['carat'],\n",
    "                               bins=[0., 0.5, 1.5, np.inf],\n",
    "                               labels=[1, 2, 3])\n",
    "convert_cat(test_df, cat_features)\n",
    "\n",
    "X_test = preprocessor.transform(test_df)\n",
    "\n",
    "pre_col.remove('price')\n",
    "\n",
    "preproces_test_df = pd.DataFrame(X_test, columns=pre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d60736e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_frame = h2o.H2OFrame(preproces_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d03a90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  875.012</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2476.94 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2328.37 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  834.542</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 5786.4  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  680.43 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">12402.5  </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2990.09 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">15258.6  </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 1862.87 </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 1 column]</pre>"
      ],
      "text/plain": [
       "  predict\n",
       "---------\n",
       "  875.012\n",
       " 2476.94\n",
       " 2328.37\n",
       "  834.542\n",
       " 5786.4\n",
       "  680.43\n",
       "12402.5\n",
       " 2990.09\n",
       "15258.6\n",
       " 1862.87\n",
       "[10 rows x 1 column]\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = aml3.predict(test_frame)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb8f0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.as_data_frame()\n",
    "pred = pred.values\n",
    "pred = pred.reshape(-1)\n",
    "\n",
    "# test_h2o = test_h2o.as_data_frame()\n",
    "# test_h2o.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4e2dacdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193573</td>\n",
       "      <td>875.012090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193574</td>\n",
       "      <td>2476.943738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193575</td>\n",
       "      <td>2328.368351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193576</td>\n",
       "      <td>834.542329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193577</td>\n",
       "      <td>5786.396569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129045</th>\n",
       "      <td>322618</td>\n",
       "      <td>3783.415807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129046</th>\n",
       "      <td>322619</td>\n",
       "      <td>2608.296078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129047</th>\n",
       "      <td>322620</td>\n",
       "      <td>7608.609007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129048</th>\n",
       "      <td>322621</td>\n",
       "      <td>5758.991942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129049</th>\n",
       "      <td>322622</td>\n",
       "      <td>4273.648261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129050 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        price\n",
       "0       193573   875.012090\n",
       "1       193574  2476.943738\n",
       "2       193575  2328.368351\n",
       "3       193576   834.542329\n",
       "4       193577  5786.396569\n",
       "...        ...          ...\n",
       "129045  322618  3783.415807\n",
       "129046  322619  2608.296078\n",
       "129047  322620  7608.609007\n",
       "129048  322621  5758.991942\n",
       "129049  322622  4273.648261\n",
       "\n",
       "[129050 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pd.DataFrame({'id': test_df.index,\n",
    "                       'price': pred})\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71a89423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('h2o_pre2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46381a9a",
   "metadata": {},
   "source": [
    "## Optuna testing\n",
    "\n",
    "##### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69786099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25a2506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3375ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = train_df.drop('price', axis = 1)\n",
    "y_final = train_df['price']\n",
    "\n",
    "X_final = preprocessor.fit_transform(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27c08bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_col = list(num_features)\n",
    "pre_col += cat_features\n",
    "\n",
    "X_final_df = pd.DataFrame(X_final, columns=pre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09d9a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': trial.suggest_categorical(\n",
    "            'tree_method', ['gpu_hist']\n",
    "        ),\n",
    "        'reg_lambda': trial.suggest_float(\n",
    "            'reg_lambda', 1e-3, 1e2, log=True\n",
    "        ),\n",
    "        'colsample_bytree': trial.suggest_float(\n",
    "            'colsample_bytree', 0.5, 1.0, step=0.1\n",
    "        ),\n",
    "        'colsample_bylevel': trial.suggest_float(\n",
    "            'colsample_bylevel', 0.5, 1.0, step=0.1\n",
    "        ),\n",
    "        'subsample': trial.suggest_float(\n",
    "            'subsample', 0.5, 1.0, step=0.1\n",
    "        ),\n",
    "        'learning_rate': trial.suggest_float(\n",
    "            'learning_rate', 1e-2, 1e0, log=True\n",
    "        ),\n",
    "        'n_estimators': trial.suggest_int(\n",
    "            'n_estimators', 50, 200, step=10\n",
    "        ),\n",
    "        'max_depth': trial.suggest_int(\n",
    "            'max_depth', 3, 9, step=2\n",
    "        ),\n",
    "        'min_child_weight': trial.suggest_int(\n",
    "            'min_child_weight', 1, 5, step=2\n",
    "        ),\n",
    "        'grow_policy': trial.suggest_categorical(\n",
    "            'grow_policy', ['lossguide']\n",
    "        )\n",
    "    }\n",
    "    kf = KFold(n_splits=5, random_state=21, shuffle=True)\n",
    "    val_split_rmse = []\n",
    "    for train_idx, val_idx in kf.split(X_final_df):\n",
    "        X_train_split, X_val_split = X_final_df.iloc[train_idx], X_final_df.iloc[val_idx]\n",
    "        Y_train_split, Y_val_split = y_final.iloc[train_idx], y_final.iloc[val_idx]\n",
    "        estimator = XGBRegressor(**params)\n",
    "        estimator.fit(X_train_split, Y_train_split, eval_set=[(X_val_split, Y_val_split)], early_stopping_rounds=5, verbose=0)\n",
    "        Y_pred_val = pd.Series(estimator.predict(X_val_split), index=X_val_split.index)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_val_split, Y_pred_val))\n",
    "        val_split_rmse.append(rmse)\n",
    "        \n",
    "    val_rmse = np.mean(val_split_rmse)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dda747ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:26:43,761] A new study created in memory with name: no-name-60e172fe-8629-422a-93a6-783177cfe25b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef3fc08d6c54975addd7270dd237fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:27:19,243] Trial 0 finished with value: 808.7995633304754 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 1.0816629630626655, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.6, 'subsample': 0.7, 'learning_rate': 0.018961668449541107, 'n_estimators': 130, 'max_depth': 9, 'min_child_weight': 1, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 808.7995633304754.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:27:22,318] Trial 1 finished with value: 700.0228649234853 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.03747697793494212, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.5, 'subsample': 0.8, 'learning_rate': 0.044212940814352876, 'n_estimators': 80, 'max_depth': 5, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 700.0228649234853.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:27:23,698] Trial 2 finished with value: 619.141609277013 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.0034708611187847516, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.6, 'subsample': 1.0, 'learning_rate': 0.9804545766204127, 'n_estimators': 70, 'max_depth': 3, 'min_child_weight': 1, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 619.141609277013.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:27:27,291] Trial 3 finished with value: 588.2054049779636 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 33.29431173172454, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.9, 'subsample': 0.8, 'learning_rate': 0.5343517396882866, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:10,320] Trial 4 finished with value: 634.2047385320302 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.003911615538716871, 'colsample_bytree': 1.0, 'colsample_bylevel': 0.9, 'subsample': 0.6, 'learning_rate': 0.023248354241521788, 'n_estimators': 130, 'max_depth': 9, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:13,489] Trial 5 finished with value: 774.1765538763278 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 3.9469997555384424, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.6, 'subsample': 0.8, 'learning_rate': 0.021753932951237367, 'n_estimators': 190, 'max_depth': 3, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:14,940] Trial 6 finished with value: 611.2238418853789 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.0033914413017361476, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.9, 'subsample': 0.7, 'learning_rate': 0.5309065349058831, 'n_estimators': 180, 'max_depth': 3, 'min_child_weight': 1, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:19,240] Trial 7 finished with value: 663.986615281858 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.748533899792722, 'colsample_bytree': 0.9, 'colsample_bylevel': 1.0, 'subsample': 0.6, 'learning_rate': 0.026255682721542568, 'n_estimators': 120, 'max_depth': 5, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:21,408] Trial 8 finished with value: 1091.597154200763 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 22.40165737666807, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.8, 'subsample': 0.5, 'learning_rate': 0.018805992210367398, 'n_estimators': 120, 'max_depth': 3, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:24,745] Trial 9 finished with value: 2114.1436937762837 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 6.4257548483587685, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.8, 'subsample': 0.7, 'learning_rate': 0.011829712918035713, 'n_estimators': 90, 'max_depth': 5, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 588.2054049779636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:30,552] Trial 10 finished with value: 580.2119225398241 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 95.7811309528612, 'colsample_bytree': 0.5, 'colsample_bylevel': 1.0, 'subsample': 1.0, 'learning_rate': 0.22248567116240786, 'n_estimators': 170, 'max_depth': 7, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 580.2119225398241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:36,011] Trial 11 finished with value: 578.6622125445845 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 92.3745877700611, 'colsample_bytree': 0.5, 'colsample_bylevel': 1.0, 'subsample': 1.0, 'learning_rate': 0.24675171794411627, 'n_estimators': 170, 'max_depth': 7, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 578.6622125445845.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:46,837] Trial 12 finished with value: 575.4909149336636 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 71.53984591862229, 'colsample_bytree': 0.5, 'colsample_bylevel': 1.0, 'subsample': 1.0, 'learning_rate': 0.11698325157758806, 'n_estimators': 170, 'max_depth': 7, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 12 with value: 575.4909149336636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:28:58,095] Trial 13 finished with value: 576.0515166968623 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 96.03474705579896, 'colsample_bytree': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'learning_rate': 0.11258682495260193, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 12 with value: 575.4909149336636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:29:11,241] Trial 14 finished with value: 575.3211550029204 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 9.36329976983981, 'colsample_bytree': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'learning_rate': 0.07995388348771042, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 14 with value: 575.3211550029204.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:29:36,201] Trial 15 finished with value: 575.3631154784084 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 8.012256394540632, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7, 'subsample': 0.9, 'learning_rate': 0.0723186523964873, 'n_estimators': 200, 'max_depth': 9, 'min_child_weight': 5, 'grow_policy': 'lossguide'}. Best is trial 14 with value: 575.3211550029204.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:30:09,392] Trial 16 finished with value: 575.3283402489284 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 6.2583036848571405, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7, 'subsample': 0.9, 'learning_rate': 0.058151561418437, 'n_estimators': 200, 'max_depth': 9, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 14 with value: 575.3211550029204.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:30:27,351] Trial 17 finished with value: 619.7962024780629 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.20729009567395812, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7, 'subsample': 0.9, 'learning_rate': 0.06573758215012508, 'n_estimators': 50, 'max_depth': 9, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 14 with value: 575.3211550029204.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:31:09,689] Trial 18 finished with value: 574.2992749020543 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 2.553793950847241, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.8, 'subsample': 0.9, 'learning_rate': 0.04480245593299995, 'n_estimators': 150, 'max_depth': 9, 'min_child_weight': 3, 'grow_policy': 'lossguide'}. Best is trial 18 with value: 574.2992749020543.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [1, 6] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 5].\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 00:31:59,413] Trial 19 finished with value: 576.8180033238582 and parameters: {'tree_method': 'gpu_hist', 'reg_lambda': 0.923073618361629, 'colsample_bytree': 1.0, 'colsample_bylevel': 0.8, 'subsample': 0.9, 'learning_rate': 0.03810028406082724, 'n_estimators': 150, 'max_depth': 9, 'min_child_weight': 1, 'grow_policy': 'lossguide'}. Best is trial 18 with value: 574.2992749020543.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_xgb, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5ba13b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_colsample_bylevel</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_grow_policy</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_reg_lambda</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>574.299275</td>\n",
       "      <td>2023-07-04 00:30:27.355196</td>\n",
       "      <td>2023-07-04 00:31:09.689215</td>\n",
       "      <td>0 days 00:00:42.334019</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>0.044802</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>2.553794</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>575.321155</td>\n",
       "      <td>2023-07-04 00:28:58.099870</td>\n",
       "      <td>2023-07-04 00:29:11.241893</td>\n",
       "      <td>0 days 00:00:13.142023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>0.079954</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>9.363300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>575.328340</td>\n",
       "      <td>2023-07-04 00:29:36.205258</td>\n",
       "      <td>2023-07-04 00:30:09.392695</td>\n",
       "      <td>0 days 00:00:33.187437</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>6.258304</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>575.363115</td>\n",
       "      <td>2023-07-04 00:29:11.246894</td>\n",
       "      <td>2023-07-04 00:29:36.200257</td>\n",
       "      <td>0 days 00:00:24.953363</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>8.012256</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>575.490915</td>\n",
       "      <td>2023-07-04 00:28:36.016931</td>\n",
       "      <td>2023-07-04 00:28:46.837100</td>\n",
       "      <td>0 days 00:00:10.820169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>0.116983</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>71.539846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number       value             datetime_start          datetime_complete  \\\n",
       "18      18  574.299275 2023-07-04 00:30:27.355196 2023-07-04 00:31:09.689215   \n",
       "14      14  575.321155 2023-07-04 00:28:58.099870 2023-07-04 00:29:11.241893   \n",
       "16      16  575.328340 2023-07-04 00:29:36.205258 2023-07-04 00:30:09.392695   \n",
       "15      15  575.363115 2023-07-04 00:29:11.246894 2023-07-04 00:29:36.200257   \n",
       "12      12  575.490915 2023-07-04 00:28:36.016931 2023-07-04 00:28:46.837100   \n",
       "\n",
       "                 duration  params_colsample_bylevel  params_colsample_bytree  \\\n",
       "18 0 days 00:00:42.334019                       0.8                      0.9   \n",
       "14 0 days 00:00:13.142023                       1.0                      0.5   \n",
       "16 0 days 00:00:33.187437                       0.7                      0.8   \n",
       "15 0 days 00:00:24.953363                       0.7                      0.8   \n",
       "12 0 days 00:00:10.820169                       1.0                      0.5   \n",
       "\n",
       "   params_grow_policy  params_learning_rate  params_max_depth  \\\n",
       "18          lossguide              0.044802                 9   \n",
       "14          lossguide              0.079954                 7   \n",
       "16          lossguide              0.058152                 9   \n",
       "15          lossguide              0.072319                 9   \n",
       "12          lossguide              0.116983                 7   \n",
       "\n",
       "    params_min_child_weight  params_n_estimators  params_reg_lambda  \\\n",
       "18                        3                  150           2.553794   \n",
       "14                        5                  200           9.363300   \n",
       "16                        3                  200           6.258304   \n",
       "15                        5                  200           8.012256   \n",
       "12                        5                  170          71.539846   \n",
       "\n",
       "    params_subsample params_tree_method     state  \n",
       "18               0.9           gpu_hist  COMPLETE  \n",
       "14               0.9           gpu_hist  COMPLETE  \n",
       "16               0.9           gpu_hist  COMPLETE  \n",
       "15               0.9           gpu_hist  COMPLETE  \n",
       "12               1.0           gpu_hist  COMPLETE  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(by='value').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd2a58ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'gpu_hist',\n",
       " 'reg_lambda': 2.553793950847241,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'colsample_bylevel': 0.8,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.04480245593299995,\n",
       " 'n_estimators': 150,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 3,\n",
       " 'grow_policy': 'lossguide'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_xgb = study.best_trial.params\n",
    "best_params_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66e4b9",
   "metadata": {},
   "source": [
    "##### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0786e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eaae715",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = train_df.drop('price', axis = 1)\n",
    "y_final = train_df['price']\n",
    "\n",
    "X_final = preprocessor.fit_transform(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a268cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_col = list(num_features)\n",
    "pre_col += cat_features\n",
    "\n",
    "X_final_df = pd.DataFrame(X_final, columns=pre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efb2147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gb(trial):\n",
    "    params = {\n",
    "        'max_iter': trial.suggest_int(\n",
    "            'max_iter', 70, 180, step=10\n",
    "        ),\n",
    "        'learning_rate': trial.suggest_float(\n",
    "            'learning_rate', 1e-2, 1e0, log=True\n",
    "        ),\n",
    "        'l2_regularization': trial.suggest_float(\n",
    "            'l2_regularization', 0.1, 1, step=0.1\n",
    "        )\n",
    "    }\n",
    "    kf = KFold(n_splits=5, random_state=21, shuffle=True)\n",
    "    val_split_rmse = []\n",
    "    for train_idx, val_idx in kf.split(X_final_df):\n",
    "        X_train_split, X_val_split = X_final_df.iloc[train_idx], X_final_df.iloc[val_idx]\n",
    "        Y_train_split, Y_val_split = y_final.iloc[train_idx], y_final.iloc[val_idx]\n",
    "        estimator = HistGradientBoostingRegressor(**params)\n",
    "        estimator.fit(X_train_split, Y_train_split)\n",
    "        Y_pred_val = pd.Series(estimator.predict(X_val_split), index=X_val_split.index)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_val_split, Y_pred_val))\n",
    "        val_split_rmse.append(rmse)\n",
    "        \n",
    "    val_rmse = np.mean(val_split_rmse)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20dbcfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 01:14:41,640] A new study created in memory with name: no-name-f06dbb2b-efa3-45b4-9c16-2f4b346dc36e\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e38de1eac28490ea0d206f230dce6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 01:14:46,902] Trial 0 finished with value: 633.1552244119691 and parameters: {'max_iter': 70, 'learning_rate': 0.043774017350668465, 'l2_regularization': 0.2}. Best is trial 0 with value: 633.1552244119691.\n",
      "[I 2023-07-04 01:14:52,107] Trial 1 finished with value: 579.3694068451466 and parameters: {'max_iter': 110, 'learning_rate': 0.17594614141662093, 'l2_regularization': 0.30000000000000004}. Best is trial 1 with value: 579.3694068451466.\n",
      "[I 2023-07-04 01:15:04,170] Trial 2 finished with value: 662.3463395528112 and parameters: {'max_iter': 170, 'learning_rate': 0.01649228324777923, 'l2_regularization': 0.5}. Best is trial 1 with value: 579.3694068451466.\n",
      "[I 2023-07-04 01:15:09,939] Trial 3 finished with value: 577.5627483886648 and parameters: {'max_iter': 80, 'learning_rate': 0.12876615995526922, 'l2_regularization': 0.8}. Best is trial 3 with value: 577.5627483886648.\n",
      "[I 2023-07-04 01:15:16,802] Trial 4 finished with value: 577.4849473968254 and parameters: {'max_iter': 90, 'learning_rate': 0.13924104077882848, 'l2_regularization': 0.9}. Best is trial 4 with value: 577.4849473968254.\n",
      "[I 2023-07-04 01:15:21,385] Trial 5 finished with value: 583.5544525476355 and parameters: {'max_iter': 80, 'learning_rate': 0.2723420304210108, 'l2_regularization': 0.5}. Best is trial 4 with value: 577.4849473968254.\n",
      "[I 2023-07-04 01:15:24,557] Trial 6 finished with value: 590.5270460528521 and parameters: {'max_iter': 70, 'learning_rate': 0.4796401386759132, 'l2_regularization': 0.9}. Best is trial 4 with value: 577.4849473968254.\n",
      "[I 2023-07-04 01:15:28,378] Trial 7 finished with value: 589.3234692677661 and parameters: {'max_iter': 70, 'learning_rate': 0.4105036907910213, 'l2_regularization': 0.1}. Best is trial 4 with value: 577.4849473968254.\n",
      "[I 2023-07-04 01:15:39,244] Trial 8 finished with value: 680.9131530440463 and parameters: {'max_iter': 140, 'learning_rate': 0.01901007539728647, 'l2_regularization': 0.2}. Best is trial 4 with value: 577.4849473968254.\n",
      "[I 2023-07-04 01:15:45,489] Trial 9 finished with value: 1342.1123930480785 and parameters: {'max_iter': 80, 'learning_rate': 0.015510864770500921, 'l2_regularization': 1.0}. Best is trial 4 with value: 577.4849473968254.\n",
      "[I 2023-07-04 01:15:54,378] Trial 10 finished with value: 576.1207665885167 and parameters: {'max_iter': 110, 'learning_rate': 0.06912786911699868, 'l2_regularization': 0.7000000000000001}. Best is trial 10 with value: 576.1207665885167.\n",
      "[I 2023-07-04 01:16:02,446] Trial 11 finished with value: 576.0857421002313 and parameters: {'max_iter': 110, 'learning_rate': 0.07133677470756836, 'l2_regularization': 0.7000000000000001}. Best is trial 11 with value: 576.0857421002313.\n",
      "[I 2023-07-04 01:16:11,644] Trial 12 finished with value: 575.7284180037358 and parameters: {'max_iter': 130, 'learning_rate': 0.060053375192846106, 'l2_regularization': 0.7000000000000001}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:16:22,692] Trial 13 finished with value: 576.1925647117122 and parameters: {'max_iter': 150, 'learning_rate': 0.04878657932263098, 'l2_regularization': 0.6}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:16:25,518] Trial 14 finished with value: 613.8270509858347 and parameters: {'max_iter': 120, 'learning_rate': 0.9680126159366235, 'l2_regularization': 0.7000000000000001}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:16:36,354] Trial 15 finished with value: 575.8045024986029 and parameters: {'max_iter': 140, 'learning_rate': 0.07022923801173286, 'l2_regularization': 0.4}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:16:50,562] Trial 16 finished with value: 583.4056090543854 and parameters: {'max_iter': 150, 'learning_rate': 0.031009300013233515, 'l2_regularization': 0.4}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:16:58,941] Trial 17 finished with value: 575.797097884264 and parameters: {'max_iter': 180, 'learning_rate': 0.07733611474765456, 'l2_regularization': 0.4}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:17:13,042] Trial 18 finished with value: 581.0956605050636 and parameters: {'max_iter': 180, 'learning_rate': 0.027981670491369782, 'l2_regularization': 0.6}. Best is trial 12 with value: 575.7284180037358.\n",
      "[I 2023-07-04 01:17:25,463] Trial 19 finished with value: 909.3748205375471 and parameters: {'max_iter': 170, 'learning_rate': 0.01091531137948552, 'l2_regularization': 0.4}. Best is trial 12 with value: 575.7284180037358.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_gb, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b3d525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_l2_regularization</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_iter</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>575.728418</td>\n",
       "      <td>2023-07-04 01:16:02.451768</td>\n",
       "      <td>2023-07-04 01:16:11.643064</td>\n",
       "      <td>0 days 00:00:09.191296</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>130</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>575.797098</td>\n",
       "      <td>2023-07-04 01:16:50.571452</td>\n",
       "      <td>2023-07-04 01:16:58.940431</td>\n",
       "      <td>0 days 00:00:08.368979</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.077336</td>\n",
       "      <td>180</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>575.804502</td>\n",
       "      <td>2023-07-04 01:16:25.523051</td>\n",
       "      <td>2023-07-04 01:16:36.353620</td>\n",
       "      <td>0 days 00:00:10.830569</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>140</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>576.085742</td>\n",
       "      <td>2023-07-04 01:15:54.383318</td>\n",
       "      <td>2023-07-04 01:16:02.446766</td>\n",
       "      <td>0 days 00:00:08.063448</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>110</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>576.120767</td>\n",
       "      <td>2023-07-04 01:15:45.494316</td>\n",
       "      <td>2023-07-04 01:15:54.378316</td>\n",
       "      <td>0 days 00:00:08.884000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.069128</td>\n",
       "      <td>110</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number       value             datetime_start          datetime_complete  \\\n",
       "12      12  575.728418 2023-07-04 01:16:02.451768 2023-07-04 01:16:11.643064   \n",
       "17      17  575.797098 2023-07-04 01:16:50.571452 2023-07-04 01:16:58.940431   \n",
       "15      15  575.804502 2023-07-04 01:16:25.523051 2023-07-04 01:16:36.353620   \n",
       "11      11  576.085742 2023-07-04 01:15:54.383318 2023-07-04 01:16:02.446766   \n",
       "10      10  576.120767 2023-07-04 01:15:45.494316 2023-07-04 01:15:54.378316   \n",
       "\n",
       "                 duration  params_l2_regularization  params_learning_rate  \\\n",
       "12 0 days 00:00:09.191296                       0.7              0.060053   \n",
       "17 0 days 00:00:08.368979                       0.4              0.077336   \n",
       "15 0 days 00:00:10.830569                       0.4              0.070229   \n",
       "11 0 days 00:00:08.063448                       0.7              0.071337   \n",
       "10 0 days 00:00:08.884000                       0.7              0.069128   \n",
       "\n",
       "    params_max_iter     state  \n",
       "12              130  COMPLETE  \n",
       "17              180  COMPLETE  \n",
       "15              140  COMPLETE  \n",
       "11              110  COMPLETE  \n",
       "10              110  COMPLETE  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(by='value').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a613da5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 130,\n",
       " 'learning_rate': 0.060053375192846106,\n",
       " 'l2_regularization': 0.7000000000000001}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_gb = study.best_trial.params\n",
    "best_params_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cc9e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b1a0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_final = train_df.drop('price', axis = 1)\n",
    "# y_final = train_df['price']\n",
    "\n",
    "# X_final = preprocessor.fit_transform(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c804dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_col = list(num_features)\n",
    "# pre_col += cat_features\n",
    "\n",
    "# X_final_df = pd.DataFrame(X_final, columns=pre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64a0d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_rf(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int(\n",
    "#             'n_estimators', 70, 180, step=10\n",
    "#         ),\n",
    "#         'max_features': trial.suggest_categorical(\n",
    "#             'max_features', ['sqrt', None]\n",
    "#         )\n",
    "#     }\n",
    "#     kf = KFold(n_splits=5, random_state=21, shuffle=True)\n",
    "#     val_split_rmse = []\n",
    "#     for train_idx, val_idx in kf.split(X_final_df):\n",
    "#         X_train_split, X_val_split = X_final_df.iloc[train_idx], X_final_df.iloc[val_idx]\n",
    "#         Y_train_split, Y_val_split = y_final.iloc[train_idx], y_final.iloc[val_idx]\n",
    "#         estimator = RandomForestRegressor(**params)\n",
    "#         estimator.fit(X_train_split, Y_train_split)\n",
    "#         Y_pred_val = pd.Series(estimator.predict(X_val_split), index=X_val_split.index)\n",
    "#         rmse = np.sqrt(mean_squared_error(Y_val_split, Y_pred_val))\n",
    "#         val_split_rmse.append(rmse)\n",
    "        \n",
    "#     val_rmse = np.mean(val_split_rmse)\n",
    "#     return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ae92608",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-04 01:46:08,099] A new study created in memory with name: no-name-359515e9-3893-4dfc-b33b-d47d51558818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5192b634e7724c37b721c8bda0fea764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2023-07-04 01:46:49,711] Trial 0 failed with parameters: {'n_estimators': 100, 'max_features': 'sqrt'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\minhm\\AppData\\Local\\Temp/ipykernel_27692/121381831.py\", line 16, in objective_xgb\n",
      "    estimator.fit(X_train_split, Y_train_split)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 473, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 184, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 379, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n",
      "[W 2023-07-04 01:46:49,713] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27692/2781664627.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minimize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \"\"\"\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27692/121381831.py\u001b[0m in \u001b[0;36mobjective_xgb\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mY_train_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mY_pred_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val_split\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    377\u001b[0m             )\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_rf, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191e8ed",
   "metadata": {},
   "source": [
    "Too time-consuming for randomforest that we get rid of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974d9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
